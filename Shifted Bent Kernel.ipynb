{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning with Kernel Methods\n",
    "\n",
    "Here we use a variational classifier to learn a nonlinear boundary using kernel methods.\n",
    "\n",
    "The variational circuit rchitecture is specified by [Farhi and Neven (2018)](https://arxiv.org/abs/1802.06002). \n",
    "The kernel map is specified by [Havlicek et al (2018)](https://arxiv.org/abs/1804.11326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "\n",
    "from scipy.stats import unitary_group\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def U_phi(x):\n",
    "    #print(x, np.shape(x))\n",
    "    # x3 := (pi - x1)(pi - x2)\n",
    "    x_0, x_1, x_2 = x[0], x[1], x[2]\n",
    "    #print(x_0, x_1, x_2)\n",
    "        \n",
    "    qml.RZ( x_0 , wires=0)\n",
    "    qml.RZ( x_1 , wires=1)\n",
    "    \n",
    "    qml.CNOT(wires=[0,1])\n",
    "    qml.RZ(x_2,wires=1)\n",
    "    qml.CNOT(wires=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer(W): # 6 weights are specified at each layer\n",
    "    \n",
    "    # euler angles\n",
    "    qml.Rot(W[0, 0], W[0, 1], W[0, 2], wires=0)\n",
    "    qml.Rot(W[1, 0], W[1, 1], W[1, 2], wires=1)\n",
    "\n",
    "    qml.CNOT(wires=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featuremap(x):\n",
    "    for i in range(2):\n",
    "        qml.Hadamard(wires=0)\n",
    "        qml.Hadamard(wires=1)\n",
    "        U_phi(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def circuit1(weights, x):\n",
    "\n",
    "    featuremap(x)\n",
    "\n",
    "    for W in weights:\n",
    "        layer(W)\n",
    "\n",
    "    return qml.expval.PauliZ(wires=0)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit2(weights, x):\n",
    "\n",
    "    featuremap(x)\n",
    "\n",
    "    for W in weights:\n",
    "        layer(W)\n",
    "\n",
    "    return qml.expval.PauliZ(wires=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variational_classifier(var, x): # x is a keyword argument -> fixed (not trained)\n",
    "    weights = var[0]\n",
    "    bias = var[1]\n",
    "\n",
    "    return circuit1(weights, x) * circuit2(weights, x) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "    #print(labels, predictions)\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(var, X, Y):\n",
    "\n",
    "    predictions = [variational_classifier(var, x) for x in X]\n",
    "    #if (len(Y) == num_data):\n",
    "    #    print(\"[(pred, label), ...]: \", list(zip(predictions, Y)))\n",
    "    return square_loss(Y, predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random unitary:  [[ 0.56480469+0.02828828j  0.00919685-0.54666223j  0.17628252-0.49642827j\n",
      "   0.2758558 -0.16630779j]\n",
      " [ 0.76026959-0.00843403j  0.14776823+0.17506096j -0.10832053+0.47307077j\n",
      "  -0.35248134-0.09830992j]\n",
      " [ 0.19169964+0.02404574j -0.6268324 +0.26471267j  0.31711591+0.29431852j\n",
      "   0.54700278+0.11525388j]\n",
      " [-0.25430813+0.0107177 j -0.06982527-0.42511976j  0.28338993+0.46846389j\n",
      "  -0.06125777-0.6678992 j]]\n",
      "det:  (1.0000000000000002-8.326672684688678e-17j)\n"
     ]
    }
   ],
   "source": [
    "random_U = unitary_group.rvs(4)\n",
    "random_U = random_U / (np.linalg.det(random_U) ** (1/4)) # so that det = 1\n",
    "\n",
    "\n",
    "print(\"random unitary: \", random_U)\n",
    "print(\"det: \", np.linalg.det(random_U))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def data_label_1(x):\n",
    "    #print(u)\n",
    "    #print(\"label the following:\", x)\n",
    "    featuremap(x)\n",
    "    qml.QubitUnitary(random_U, wires=[0,1])\n",
    "    \n",
    "    return qml.expval.PauliZ(wires=0)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def data_label_2(x):\n",
    "    #print(\"label the following:\", x)\n",
    "    featuremap(x)\n",
    "    qml.QubitUnitary(random_U, wires=[0,1])\n",
    "    \n",
    "    return qml.expval.PauliZ(wires=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(thresh):\n",
    "    #thresh = 0.3\n",
    "\n",
    "    X = np.array([])\n",
    "    Y = np.array([])\n",
    "    ctr = 0 # num valid data pts\n",
    "    maxval = 0.0\n",
    "    minval = 0.0\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    while ctr < 40:\n",
    "        x = np.random.rand(2) * 2 * np.pi\n",
    "        x = np.append(x, (np.pi - x[0]) * (np.pi - x[1]))\n",
    "        y_1 = data_label_1(x)\n",
    "        y_2 = data_label_2(x)\n",
    "        #print(y_1, y_2, y_1 * y_2)\n",
    "        if (np.abs(y_1 * y_2) > maxval):\n",
    "            maxval = y_1 * y_2\n",
    "            #print(\"new max separation: \", maxval)\n",
    "        elif (y_1 * y_2 < minval):\n",
    "            minval = y_1 * y_2\n",
    "            #print(\"new min separation: \", minval)\n",
    "\n",
    "        if y_1 * y_2 > thresh:\n",
    "            Y = np.append(Y, +1)\n",
    "            X = np.append(X, x)\n",
    "            ctr += 1\n",
    "            #print(\"+1\")\n",
    "        elif y_1 * y_2 < -1 * thresh:\n",
    "            Y = np.append(Y, -1)\n",
    "            X = np.append(X, x)\n",
    "            ctr += 1\n",
    "            #print(\"-1\")\n",
    "            \n",
    "    X = X.reshape(-1, 3)\n",
    "    print(\"Data: \", list(zip(X, Y)))\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_train_test(X, Y):\n",
    "    global num_data\n",
    "    num_data = len(Y)\n",
    "    global num_train\n",
    "    num_train = int(0.5 * num_data)\n",
    "\n",
    "    print(\"size data, size train: \", num_data, num_train)\n",
    "\n",
    "    index = np.random.permutation(range(num_data))\n",
    "    X_train = X[index[:num_train]]\n",
    "    Y_train = Y[index[:num_train]]\n",
    "\n",
    "    X_test = X[index[num_train:]]\n",
    "    Y_test = Y[index[num_train:]]\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 2\n",
    "num_layers = 6\n",
    "var_init = (0.01 * np.random.randn(num_layers, num_qubits, 3), 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(thresh):\n",
    "    X, Y = gen_data(thresh)\n",
    "    X_train, Y_train, X_test, Y_test = divide_train_test(X, Y)\n",
    "\n",
    "    opt = NesterovMomentumOptimizer(0.01)\n",
    "    batch_size = 5\n",
    "\n",
    "    # train the variational classifier\n",
    "    var = var_init\n",
    "    \n",
    "    test_accuracies = []\n",
    "    train_accuracies = []\n",
    "    costs = []\n",
    "    for it in range(100):\n",
    "\n",
    "        # Update the weights by one optimizer step\n",
    "        batch_index = np.random.randint(0, num_train, (batch_size, ))\n",
    "        X_train_batch = X_train[batch_index]\n",
    "        Y_train_batch = Y_train[batch_index]\n",
    "        var = opt.step(lambda v: cost(v, X_train_batch, Y_train_batch), var)\n",
    "\n",
    "        # Compute predictions on train and validation set\n",
    "        predictions_train = [np.sign(variational_classifier(var, f)) for f in X_train]\n",
    "        predictions_test = [np.sign(variational_classifier(var, f)) for f in X_test]\n",
    "\n",
    "        # Compute accuracy on train and validation set\n",
    "        acc_train = accuracy(Y_train, predictions_train)\n",
    "        acc_test = accuracy(Y_test, predictions_test)\n",
    "        \n",
    "        # Compute cost on all samples\n",
    "        c = cost(var, X, Y)\n",
    "        \n",
    "        costs.append(c)\n",
    "        test_accuracies.append(acc_train)\n",
    "        train_accuracies.append(acc_test)\n",
    "        \n",
    "        print(\"Iter: {:5d} | Cost: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f} \"\n",
    "              \"\".format(it+1, c, acc_train, acc_test))\n",
    "        \n",
    "    return train_accuracies, test_accuracies, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.0, 0.1, 0.2, 0.3]\n",
    "thresh_test_accuracies = []\n",
    "thresh_train_accuracies = []\n",
    "thresh_costs = []\n",
    "for thresh in thresholds:\n",
    "        print(\"New threshold: \", thresh)\n",
    "        trn_ac, tst_ac, costs = train_and_test(thresh)\n",
    "        thresh_train_accuracies.append(trn_ac)\n",
    "        thresh_test_accuracies.append(tst_ac)\n",
    "        thresh_costs.append(costs)\n",
    "        \n",
    "print(thresh_test_accuracies)\n",
    "print(thresh_train_accuracies)\n",
    "print(thresh_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(20,20)) \n",
    "\n",
    "num_thresh = len(thresholds)\n",
    "for i in range(num_thresh):\n",
    "    plt.subplot(num_thresh, 1, i + 1)\n",
    "    plt.plot(thresh_train_accuracies[i], '-', label='Training accuracy')\n",
    "    plt.plot(thresh_test_accuracies[i], '-', label='Test accuracy')\n",
    "\n",
    "    plt.title('Data Separation Threshold %0.2f' % thresholds[i])\n",
    "    plt.xlabel('# of iterations')\n",
    "    plt.ylabel('Classification accuracy')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(20,20)) \n",
    "\n",
    "num_thresh = len(thresholds)\n",
    "for i in range(num_thresh):\n",
    "    plt.plot(thresh_costs[i], '-', label='Data Separation Threshold %0.2f' % thresholds[i])\n",
    "\n",
    "plt.xlabel('# of iterations')\n",
    "plt.ylabel('L2 Loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
